{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from Common import NeuralNet, fit, FNO2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GLOBAL PARAMETERS #####\n",
    "\n",
    "d = 3\n",
    "\n",
    "x1_min, x1_max = -1.0, 1.0\n",
    "x2_min, x2_max = -1.0, 1.0\n",
    "\n",
    "mu_min, mu_max = -1.0, 1.0\n",
    "\n",
    "final_time = 0.1\n",
    "\n",
    "# Define the initial condition function\n",
    "def u0(input_vector):\n",
    "    u = 0\n",
    "    for m in range(1, d+1):\n",
    "        u -= input_vector[2+m-1] * np.sin(np.pi * m * input_vector[0]) * np.sin(np.pi * m * input_vector[1]) / np.sqrt(m)\n",
    "    return u / d\n",
    "\n",
    "# Define the solution function\n",
    "def u(t, input_vector):\n",
    "    u = 0\n",
    "    for m in range(1, d+1):\n",
    "        u -= np.exp(-(np.pi * m) ** 2 * t) * input_vector[2+m-1] * np.sin(np.pi * m * input_vector[0]) * np.sin(np.pi * m * input_vector[1]) / np.sqrt(m)\n",
    "    return u / d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GENERATE TRAINING INPUT #####\n",
    "\n",
    "num_positions = 32**2\n",
    "num_params = 32**d\n",
    "\n",
    "# positions\n",
    "\n",
    "soboleng_positions = torch.quasirandom.SobolEngine(dimension=2, scramble=True)\n",
    "sobol_positions = soboleng_positions.draw(num_positions).numpy()\n",
    "\n",
    "sobol_positions[:, 0] *= (x1_max-x1_min)\n",
    "sobol_positions[:, 0] += x1_min \n",
    "sobol_positions[:, 1] *= (x2_max-x2_min) \n",
    "sobol_positions[:, 1] += x2_min\n",
    "\n",
    "# parameters\n",
    "\n",
    "soboleng_params = torch.quasirandom.SobolEngine(dimension=d, scramble=True)\n",
    "sobol_params = soboleng_params.draw(num_params).numpy()\n",
    "# sobol_params = torch.rand((num_params, d))\n",
    "\n",
    "for m in range(d):\n",
    "    sobol_params[:, m] = sobol_params[:, m] * (mu_max-mu_min) + mu_min \n",
    "\n",
    "training_inputs = np.zeros((num_positions*num_params, 2+d))\n",
    "training_inputs[:, 0] = np.tile(sobol_positions[:, 0], num_params)\n",
    "training_inputs[:, 1] = np.tile(sobol_positions[:, 1], num_params)\n",
    "for m in range(d):\n",
    "    training_inputs[:, 2+m] = np.tile(sobol_params[:, m], num_positions).reshape(num_positions, num_params).transpose().flatten()\n",
    "\n",
    "print(training_inputs.shape)\n",
    "np.save(\"data/training_inputs.npy\", training_inputs)\n",
    "\n",
    "\n",
    "##### GENERATE TRAINING OUTPUT #####\n",
    "\n",
    "training_outputs = u(final_time, training_inputs.transpose())\n",
    "print(training_outputs.shape)\n",
    "np.save(\"data/training_outputs.npy\", training_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = np.load(\"data/training_inputs.npy\")\n",
    "output_train = np.load(\"data/training_outputs.npy\")\n",
    "\n",
    "print(input_train.shape, output_train.shape)\n",
    "\n",
    "in_test = input_train[:num_positions, :]\n",
    "X_test, Y_test = in_test[:, 0], in_test[:, 1]\n",
    "out_test = output_train[:num_positions]\n",
    "_min, _max = np.min(out_test), np.max(out_test)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 5))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "surf = ax.plot_trisurf(X_test, Y_test, out_test, cmap=cm.jet, linewidth=0.1)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_title('Solution at final time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FINAL TRAINING DATA RETYPING #####\n",
    "\n",
    "input_train_torch = torch.tensor(input_train, dtype=torch.float32)\n",
    "output_train_torch = torch.tensor(output_train, dtype=torch.float32)\n",
    "input_train_torch = input_train_torch.to(device)\n",
    "output_train_torch = output_train_torch.to(device)\n",
    "training_dataset = TensorDataset(torch.tensor(input_train_torch), torch.tensor(output_train_torch))\n",
    "training_dataset_dl = DataLoader(training_dataset, batch_size=2048, shuffle=True)\n",
    "\n",
    "##### MODEL DEFINITION #####\n",
    "\n",
    "neurons_per_layer = 26\n",
    "num_hidden_layers = 3\n",
    "\n",
    "model = NeuralNet(\n",
    "    input_dimension=2+d,\n",
    "    output_dimension=1,\n",
    "    n_hidden_layers=num_hidden_layers,\n",
    "    neurons=neurons_per_layer,\n",
    "    regularization_exp=0,\n",
    "    regularization_param=0,\n",
    "    retrain_seed=1\n",
    "    )\n",
    "model = model.to(device)\n",
    "pytorch_total_params_parametric = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"number of trainable parameters:\", pytorch_total_params_parametric)\n",
    "##### TRAINING #####\n",
    "\n",
    "num_weights = (num_hidden_layers-1)*(neurons_per_layer+1)*neurons_per_layer + (2+d+1)*neurons_per_layer + (neurons_per_layer+1)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"number of degrees of freedom:\", num_weights, pytorch_total_params)\n",
    "\n",
    "\n",
    "learning_rate = 2e-3\n",
    "num_epochs = 2\n",
    "\n",
    "optimizer_ADAM = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=float(learning_rate)\n",
    "    )\n",
    "\n",
    "history, mse, epoch_time = fit(\n",
    "    model=model,\n",
    "    training_set=training_dataset_dl,\n",
    "    num_epochs=num_epochs,\n",
    "    optimizer=optimizer_ADAM,\n",
    "    p=2,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot history vs epoch and history vs epoch * epoch_time using subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot history vs epoch\n",
    "axes[0].plot(np.arange(len(mse)) + 1, mse)\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"MSE Loss vs Epoch\")\n",
    "\n",
    "# Plot history vs epoch * epoch_time\n",
    "\n",
    "axes[1].plot((np.arange(len(mse)) + 1) * epoch_time, mse)\n",
    "axes[1].set_xlabel(\"Time (s)\")\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_ylabel(\"Loss\")\n",
    "axes[1].set_title(\"MSE Loss vs Time\")\n",
    "# plt.ylim([5e-4, 2e-1 ])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Average epoch time =  \" + str(epoch_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GENERATE TESTING DATA #####\n",
    "\n",
    "num_positions_test = 10000\n",
    "num_params_test = 1\n",
    "model = model.cpu()\n",
    "# positions\n",
    "\n",
    "positions_test = np.random.random((num_positions_test,2))\n",
    "\n",
    "positions_test[:, 0] *= (x1_max-x1_min)\n",
    "positions_test[:, 0] += x1_min \n",
    "positions_test[:, 1] *= (x2_max-x2_min) \n",
    "positions_test[:, 1] += x2_min\n",
    "\n",
    "# parameters\n",
    "\n",
    "mu_test = torch.rand((1,d))\n",
    "for m in range(d):\n",
    "    mu_test[:, m] *= (mu_max-mu_min) \n",
    "    mu_test[:, m] += mu_min \n",
    "print(\"test parameters:\", mu_test)\n",
    "\n",
    "test_inputs = np.zeros((num_positions_test*num_params_test, 2+d))\n",
    "test_inputs[:, 0] = np.tile(positions_test[:, 0], num_params_test)\n",
    "test_inputs[:, 1] = np.tile(positions_test[:, 1], num_params_test)\n",
    "for m in range(d):\n",
    "    test_inputs[:, 2+m] = np.tile(mu_test[:, m], num_positions_test).reshape(num_positions_test, num_params_test).transpose().flatten()\n",
    "\n",
    "prediction = np.array([model.forward(torch.tensor(test_inputs[i, :], dtype=torch.float32)).detach().item() for i in range(num_positions_test)])\n",
    "ground_truth = u(final_time, test_inputs.transpose())\n",
    "\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "# surf = ax.plot_trisurf(test_inputs[:, 1], test_inputs[:, 1], prediction, cmap=cm.jet, linewidth=0.1)\n",
    "# fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "im1 = ax1.scatter(test_inputs[:, 0], test_inputs[:, 1], c=prediction, cmap='viridis')\n",
    "plt.colorbar(im1)\n",
    "ax1.set_xlabel('X1')\n",
    "ax1.set_ylabel('X2')\n",
    "ax1.set_title('NN Prediction')\n",
    "\n",
    "ax2 = fig.add_subplot(132)\n",
    "# surf = ax.plot_trisurf(test_inputs[:, 1], test_inputs[:, 1], ground_truth, cmap=cm.jet, linewidth=0.1)\n",
    "# fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "im2 = ax2.scatter(test_inputs[:, 0], test_inputs[:, 1], c=ground_truth, cmap='viridis')\n",
    "plt.colorbar(im2)\n",
    "ax2.set_xlabel('X1')\n",
    "ax2.set_ylabel('X2')\n",
    "ax2.set_title('Ground truth')\n",
    "\n",
    "ax3 = fig.add_subplot(133)\n",
    "# surf = ax.plot_trisurf(test_inputs[:, 1], test_inputs[:, 1], ground_truth, cmap=cm.jet, linewidth=0.1)\n",
    "# fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "im3 = ax3.scatter(test_inputs[:, 0], test_inputs[:, 1], c=np.abs(ground_truth-prediction), cmap='viridis')\n",
    "plt.colorbar(im3)\n",
    "ax3.set_xlabel('X1')\n",
    "ax3.set_ylabel('X2')\n",
    "ax3.set_title('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operator approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretization = 32\n",
    "\n",
    "x1_points = torch.linspace(x1_min, x1_max, discretization)\n",
    "x2_points = torch.linspace(x2_min, x2_max, discretization)\n",
    "\n",
    "position_grid = torch.stack(torch.meshgrid(x1_points, x2_points),axis=2).reshape((discretization, discretization, 2)).transpose(0, 1)\n",
    "\n",
    "d = 2\n",
    "n_samples = 32**d\n",
    "\n",
    "param_samples = torch.rand((n_samples, d))*(mu_max - mu_min) + mu_min\n",
    "\n",
    "fno_input_positions = torch.tile(position_grid.reshape((1, discretization**2, 2)), (n_samples, 1, 1))\n",
    "# print(fno_input_positions.shape)\n",
    "fno_input_params = torch.tile(param_samples.reshape(n_samples, 1, d), (1, discretization**2, 1))\n",
    "# print(fno_input_params.shape)\n",
    "fno_input_vectors = torch.concatenate((fno_input_positions, fno_input_params), axis=-1).reshape(n_samples*discretization*discretization, 2+d)\n",
    "# print(fno_input_vectors.shape)\n",
    "\n",
    "fno_input_train = torch.concatenate(\n",
    "    (\n",
    "        u0(np.transpose(fno_input_vectors)).reshape((n_samples, discretization, discretization, 1)), \n",
    "        fno_input_vectors[:, 0].reshape((n_samples, discretization, discretization, 1)),\n",
    "        fno_input_vectors[:, 1].reshape((n_samples, discretization, discretization, 1))\n",
    "    ), \n",
    "    axis=-1)\n",
    "fno_output_train = u(final_time, np.transpose(fno_input_vectors)).reshape((n_samples, discretization, discretization, 1))\n",
    "\n",
    "print(\"input:\", fno_input_train.shape)\n",
    "print(\"output:\", fno_output_train.shape)\n",
    "\n",
    "# np.savetxt(\"fno_input_vectors.csv\", np.array(fno_input_vectors.detach()), delimiter=',')\n",
    "\n",
    "n_train = int(0.8*n_samples)\n",
    "print(\"n_train = \", n_train)\n",
    "\n",
    "input_function_train = fno_input_train[:n_train, :, :, :]\n",
    "output_function_train = fno_output_train[:n_train, :, :, :]\n",
    "input_function_test = fno_input_train[n_train:, :, :, :]\n",
    "output_function_test = fno_output_train[n_train:, :, :, :]\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "training_set = DataLoader(TensorDataset(input_function_train, output_function_train), batch_size=batch_size, shuffle=False)\n",
    "testing_set = DataLoader(TensorDataset(input_function_test, output_function_test), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(input_function_train.shape)\n",
    "print(output_function_train.shape)\n",
    "print(input_function_test.shape)\n",
    "print(output_function_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0002\n",
    "\n",
    "epochs = 10\n",
    "step_size = 20\n",
    "gamma = 0.5\n",
    "\n",
    "modes = 2\n",
    "width = 8\n",
    "n_layers = 2\n",
    "\n",
    "fno_architecture = {\n",
    "    \"modes\": modes,\n",
    "    \"width\": width,\n",
    "    \"n_layers\": n_layers,\n",
    "    \"retrain_fno\": 1\n",
    "}\n",
    "\n",
    "\n",
    "fno = FNO2d(fno_architecture)\n",
    "\n",
    "pytorch_total_params_fno = sum(p.numel() for p in fno.parameters() if p.requires_grad)\n",
    "print(\"number of trainable parameters:\", pytorch_total_params_fno)\n",
    "\n",
    "num_weights = (3+1)*width + n_layers*((width+1)*width + 2*width*width*modes*modes) + (width+1)*128 + (128+1)\n",
    "pytorch_total_params = sum(p.numel() for p in fno.parameters() if p.requires_grad)\n",
    "print(\"number of degrees of freedom:\", num_weights, pytorch_total_params)\n",
    "\n",
    "optimizer = optim.Adam(fno.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "train_loss_mse = []\n",
    "test_loss_l2 = []\n",
    "epoch_time_list = []\n",
    "\n",
    "\n",
    "l = torch.nn.MSELoss()\n",
    "freq_print = 1\n",
    "for epoch in range(epochs):\n",
    "    t0 = time.time()\n",
    "    train_mse = 0.0\n",
    "    for step, (input_batch, output_batch) in enumerate(training_set):\n",
    "        optimizer.zero_grad()\n",
    "        output_pred_batch = fno(input_batch).squeeze(2)\n",
    "        loss_f = l(output_pred_batch, output_batch)\n",
    "        loss_f.backward()\n",
    "        optimizer.step()\n",
    "        train_mse += loss_f.item()\n",
    "    train_mse /= len(training_set)\n",
    "    train_loss_mse.append(train_mse)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fno.eval()\n",
    "        test_relative_l2 = 0.0\n",
    "        for step, (input_batch, output_batch) in enumerate(testing_set):\n",
    "            output_pred_batch = fno(input_batch).squeeze(2)\n",
    "            loss_f = (torch.mean((output_pred_batch - output_batch) ** 2) / torch.mean(output_batch ** 2)) ** 0.5 * 100\n",
    "            test_relative_l2 += loss_f.item()\n",
    "        test_relative_l2 /= len(testing_set)\n",
    "        test_loss_l2.append(test_relative_l2)\n",
    "    ep_time = time.time() - t0\n",
    "    epoch_time_list.append(ep_time)\n",
    "    if epoch % freq_print == 0: print(\"######### Epoch:\", epoch, \" ######### Train Loss:\", train_mse, \" ######### Relative L2 Test Norm:\", test_relative_l2)\n",
    "time_x = []\n",
    "for i in range(len(epoch_time_list)):\n",
    "    time_x.append(sum(epoch_time_list[:i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2, ax3) = plt.subplots(1,3,figsize=(18,6))\n",
    "plt.ylim([5e-4, 2e-1 ])\n",
    "ax1.plot(train_loss_mse)\n",
    "ax1.set_title(\"Training loss (MSE) vs epoch\")\n",
    "ax1.set_yscale('log')\n",
    "ax2.plot(test_loss_l2)\n",
    "ax2.set_title(\"Test loss (L2)\")\n",
    "ax2.set_yscale('log')\n",
    "ax3.plot(time_x, train_loss_mse)\n",
    "ax3.set_title(\"Training loss (MSE) vs Time\")\n",
    "ax3.set_yscale('log')\n",
    "print(\"Average epoch time =  \" + str(np.average(np.array(epoch_time_list))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ON A TRAINING SAMPLE\n",
    "\n",
    "k = 3\n",
    "print(param_samples[k, :])\n",
    "\n",
    "test_input = fno_input_train[k:k+1, :, :, :]\n",
    "\n",
    "prediction = fno.forward(test_input).reshape((discretization, discretization))\n",
    "ground_truth = fno_output_train[k, :, :, :].reshape((discretization, discretization))\n",
    "\n",
    "print(prediction.shape)\n",
    "print(ground_truth.shape)\n",
    "\n",
    "xx, yy = np.meshgrid(x1_points, x2_points)\n",
    "\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "\n",
    "im1 = ax1.scatter(xx, yy, c=prediction.detach().numpy(), cmap='viridis')\n",
    "ax1.set_title(\"FNO prediction\")\n",
    "plt.colorbar(im1)\n",
    "ax2 = fig.add_subplot(132)\n",
    "im2 = ax2.scatter(xx, yy, c=ground_truth.detach().numpy(), cmap='viridis')\n",
    "ax2.set_title(\"Ground truth\")\n",
    "plt.colorbar(im2)\n",
    "ax3 = fig.add_subplot(133)\n",
    "im3 = ax3.scatter(xx, yy, c=np.abs(ground_truth.detach().numpy()-prediction.detach().numpy()), cmap='viridis')\n",
    "ax3.set_title(\"Error\")\n",
    "plt.colorbar(im3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ON A NEW SAMPLE\n",
    "\n",
    "n_samples = 1\n",
    "\n",
    "param_samples = torch.rand((n_samples, d))*(mu_max - mu_min) + mu_min\n",
    "print(param_samples)\n",
    "\n",
    "fno_input_positions = torch.tile(position_grid.reshape((1, discretization**2, 2)), (n_samples, 1, 1))\n",
    "# print(fno_input_positions.shape)\n",
    "fno_input_params = torch.tile(param_samples.reshape(n_samples, 1, d), (1, discretization**2, 1))\n",
    "# print(fno_input_params.shape)\n",
    "fno_input_vectors = torch.concatenate((fno_input_positions, fno_input_params), axis=-1).reshape(n_samples*discretization*discretization, 2+d)\n",
    "# print(fno_input_vectors.shape)\n",
    "\n",
    "fno_input_train = torch.concatenate(\n",
    "    (\n",
    "        u0(np.transpose(fno_input_vectors)).reshape((n_samples, discretization, discretization, 1)), \n",
    "        fno_input_vectors[:, 0].reshape((n_samples, discretization, discretization, 1)),\n",
    "        fno_input_vectors[:, 1].reshape((n_samples, discretization, discretization, 1))\n",
    "    ), \n",
    "    axis=-1)\n",
    "fno_output_train = u(final_time, np.transpose(fno_input_vectors)).reshape((n_samples, discretization, discretization, 1))\n",
    "\n",
    "\n",
    "prediction = fno.forward(fno_input_train).reshape((discretization, discretization))\n",
    "ground_truth = fno_output_train[0, :, :, :].reshape((discretization, discretization))\n",
    "\n",
    "print(prediction.shape)\n",
    "print(ground_truth.shape)\n",
    "\n",
    "xx, yy = np.meshgrid(x1_points, x2_points)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18,5))\n",
    "\n",
    "im1 = ax1.scatter(xx, yy, c=prediction.detach().numpy(), cmap='viridis')\n",
    "ax1.set_title(\"FNO prediction\")\n",
    "plt.colorbar(im1)\n",
    "im2 = ax2.scatter(xx, yy, c=ground_truth.detach().numpy(), cmap='viridis')\n",
    "ax2.set_title(\"Ground truth\")\n",
    "plt.colorbar(im2)\n",
    "im3 = ax3.scatter(xx, yy, c=np.abs(ground_truth.detach().numpy()-prediction.detach().numpy()), cmap='viridis')\n",
    "ax3.set_title(\"Error\")\n",
    "plt.colorbar(im3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
