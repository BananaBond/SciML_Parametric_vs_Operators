{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from Common import NeuralNet, fit, FNO2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GLOBAL PARAMETERS #####\n",
    "\n",
    "d = 1\n",
    "\n",
    "x1_min, x1_max = -0, 1.0\n",
    "x2_min, x2_max = -0.2, 1.0\n",
    "\n",
    "dist_min, dist_max = 0.8, 1.2\n",
    "# wl_min,   wl_max   = 20, 25\n",
    "\n",
    "freq = 12\n",
    "\n",
    "# Define the initial condition function\n",
    "def u0(input_vector):\n",
    "    u = np.abs(input_vector[0] - input_vector[2]/2.) < 0.1\n",
    "    u = np.logical_or(u, np.abs(input_vector[0] + input_vector[2]/2.) < 0.1)\n",
    "    u = np.logical_and(np.abs(input_vector[1]) < 0.1, np.logical_not(u))\n",
    "    return u\n",
    "\n",
    "\n",
    "# Define the solution function\n",
    "def u(input_vector):\n",
    "    u = np.sin(np.sqrt((input_vector[0] - input_vector[2]/2.)**2 + input_vector[1]**2) * freq) * 0.5\n",
    "    u += np.sin(np.sqrt((input_vector[0] + input_vector[2]/2.)**2 + input_vector[1]**2) * freq) * 0.5\n",
    "    u *= input_vector[1] >= 0\n",
    "    u += (input_vector[1] < 0) * np.sin(input_vector[1] * freq)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GENERATE TRAINING INPUT #####\n",
    "\n",
    "num_positions = 64**2\n",
    "num_params = 32\n",
    "\n",
    "# positions\n",
    "\n",
    "soboleng_positions = torch.quasirandom.SobolEngine(dimension=2, scramble=True)\n",
    "input_positions = soboleng_positions.draw(num_positions*num_params).numpy()\n",
    "\n",
    "input_positions[:, 0] *= (x1_max-x1_min)\n",
    "input_positions[:, 0] += x1_min \n",
    "input_positions[:, 1] *= (x2_max-x2_min) \n",
    "input_positions[:, 1] += x2_min\n",
    "\n",
    "# parameters\n",
    "\n",
    "soboleng_params = torch.quasirandom.SobolEngine(dimension=d, scramble=True)\n",
    "sobol_params = soboleng_params.draw(num_params).numpy()\n",
    "# sobol_params = torch.rand((num_params, d))\n",
    "\n",
    "\n",
    "sobol_params[:, 0] = sobol_params[:, 0] * (dist_max-dist_min) + dist_min \n",
    "# sobol_params[:, 0] = sobol_params[:, 0] * (wl_max-wl_min) + wl_min \n",
    "\n",
    "training_inputs = np.zeros((num_positions*num_params, 2+d))\n",
    "training_inputs[:, 0] = input_positions[:, 0]\n",
    "training_inputs[:, 1] = input_positions[:, 1]\n",
    "\n",
    "for m in range(d):\n",
    "    training_inputs[:, 2+m] = np.tile(sobol_params[:, m], num_positions).reshape(num_positions, num_params).transpose().flatten()\n",
    "\n",
    "print(training_inputs.shape)\n",
    "np.save(\"data/training_inputs.npy\", training_inputs)\n",
    "\n",
    "\n",
    "##### GENERATE TRAINING OUTPUT #####\n",
    "\n",
    "training_outputs = u(training_inputs.transpose())\n",
    "print(training_outputs.shape)\n",
    "np.save(\"data/training_outputs.npy\", training_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = np.load(\"data/training_inputs.npy\")\n",
    "output_train = np.load(\"data/training_outputs.npy\")\n",
    "\n",
    "print(input_train.shape, output_train.shape)\n",
    "\n",
    "param_idx = 8\n",
    "\n",
    "in_test = input_train[num_positions*param_idx:num_positions*(param_idx+1), :]\n",
    "X_test, Y_test = in_test[:, 0], in_test[:, 1]\n",
    "print(in_test[:, 2])\n",
    "out_test = output_train[num_positions*param_idx:num_positions*(param_idx+1)]\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "surf = ax.scatter(X_test, Y_test, c=out_test, cmap=cm.jet, s=16)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_title('Solution at final time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FINAL TRAINING DATA RETYPING #####\n",
    "\n",
    "input_train_torch = torch.tensor(input_train, dtype=torch.float32)\n",
    "output_train_torch = torch.tensor(output_train, dtype=torch.float32)\n",
    "training_dataset = TensorDataset(torch.tensor(input_train_torch), torch.tensor(output_train_torch))\n",
    "training_dataset_dl = DataLoader(training_dataset, batch_size=4096, shuffle=True)\n",
    "\n",
    "##### MODEL DEFINITION #####\n",
    "\n",
    "model = NeuralNet(\n",
    "    input_dimension=2+d,\n",
    "    output_dimension=1,\n",
    "    n_hidden_layers=4,\n",
    "    neurons=32,\n",
    "    regularization_exp=0,\n",
    "    regularization_param=0,\n",
    "    retrain_seed=1\n",
    "    )\n",
    "\n",
    "##### TRAINING #####\n",
    "\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 10\n",
    "\n",
    "optimizer_ADAM = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=float(learning_rate)\n",
    "    )\n",
    "\n",
    "history, epoch_time = fit(\n",
    "    model=model,\n",
    "    training_set=training_dataset_dl,\n",
    "    num_epochs=num_epochs,\n",
    "    optimizer=optimizer_ADAM,\n",
    "    p=2,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "plt.plot(history)\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GENERATE TESTING DATA #####\n",
    "\n",
    "num_positions_test = 10000\n",
    "num_params_test    = 1\n",
    "\n",
    "# positions\n",
    "\n",
    "positions_test = np.random.random((num_positions_test,2))\n",
    "\n",
    "positions_test[:, 0] *= (x1_max-x1_min)\n",
    "positions_test[:, 0] += x1_min \n",
    "positions_test[:, 1] *= (x2_max-x2_min) \n",
    "positions_test[:, 1] += x2_min\n",
    "\n",
    "# parameters\n",
    "\n",
    "mu_test = torch.rand((1,d))\n",
    "\n",
    "mu_test[:, 0] = mu_test[:, 0] * (dist_max-dist_min) + dist_min \n",
    "# mu_test[:, 0] = mu_test[:, 0] * (wl_max-wl_min) + wl_min \n",
    "\n",
    "print(f\"Slits distance: {mu_test[0]}\")\n",
    "\n",
    "test_inputs = np.zeros((num_positions_test*num_params_test, 2+d))\n",
    "test_inputs[:, 0] = np.tile(positions_test[:, 0], num_params_test)\n",
    "test_inputs[:, 1] = np.tile(positions_test[:, 1], num_params_test)\n",
    "for m in range(d):\n",
    "    test_inputs[:, 2+m] = np.tile(mu_test[:, m], num_positions_test).reshape(num_positions_test, num_params_test).transpose().flatten()\n",
    "\n",
    "prediction = np.array([model.forward(torch.tensor(test_inputs[i, :], dtype=torch.float32)).detach().item() for i in range(num_positions_test)])\n",
    "ground_truth = u(test_inputs.transpose())\n",
    "\n",
    "fig = plt.figure(figsize=(12, 7))\n",
    "\n",
    "mirrored_inputs = np.concatenate((test_inputs, test_inputs * np.array([-1, 1, 1])), axis=0)\n",
    "mirrored_prediction = np.concatenate((prediction, prediction), axis=0)\n",
    "mirrored_ground_truth = np.concatenate((ground_truth, ground_truth), axis=0)\n",
    "\n",
    "dot_size = 5\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "im1 = ax1.scatter(mirrored_inputs[:, 0], mirrored_inputs[:, 1], c=mirrored_prediction, cmap=cm.jet, s=dot_size, vmin=-1, vmax=1)\n",
    "plt.colorbar(im1)\n",
    "ax1.set_xlabel('X1')\n",
    "ax1.set_ylabel('X2')\n",
    "ax1.set_title('NN Prediction')\n",
    "ax1.set_xlim(-x1_max, x1_max)\n",
    "ax1.set_ylim(x2_min, x2_max)\n",
    "ax1.set_aspect(1)\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "im2 = ax2.scatter(mirrored_inputs[:, 0], mirrored_inputs[:, 1], c=mirrored_ground_truth, cmap=cm.jet, s=dot_size, vmin=-1, vmax=1)\n",
    "plt.colorbar(im2)\n",
    "ax2.set_xlabel('X1')\n",
    "ax2.set_ylabel('X2')\n",
    "ax2.set_title('Ground truth')\n",
    "ax2.set_xlim(-x1_max, x1_max)\n",
    "ax2.set_ylim(x2_min, x2_max)\n",
    "ax2.set_aspect(1)\n",
    "\n",
    "ax3 = fig.add_subplot(224)\n",
    "im3 = ax3.scatter(mirrored_inputs[:, 0], mirrored_inputs[:, 1], c=np.abs(mirrored_ground_truth - mirrored_prediction), cmap=cm.jet, s=dot_size)\n",
    "plt.colorbar(im3)\n",
    "ax3.set_xlabel('X1')\n",
    "ax3.set_ylabel('X2')\n",
    "ax3.set_title('Error')\n",
    "ax3.set_xlim(-x1_max, x1_max)\n",
    "ax3.set_ylim(x2_min, x2_max)\n",
    "ax3.set_aspect(1)\n",
    "\n",
    "ax4 = fig.add_subplot(223)\n",
    "im4 = ax4.scatter(mirrored_inputs[:, 0], mirrored_inputs[:, 1], c=u0(mirrored_inputs.T), cmap=cm.binary, s=dot_size)\n",
    "plt.colorbar(im4)\n",
    "ax4.set_xlabel('X1')\n",
    "ax4.set_ylabel('X2')\n",
    "ax4.set_title(f'Input mu={mu_test.numpy()[0,0]:2f}')\n",
    "ax4.set_xlim(-x1_max, x1_max)\n",
    "ax4.set_ylim(x2_min, x2_max)\n",
    "ax4.set_aspect(1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operator approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 2D FOURIER LAYER #####\n",
    "\n",
    "class SpectralConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super(SpectralConv2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul2d(self, input, weights):\n",
    "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
    "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        # Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfft2(x)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-2), x.size(-1) // 2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
    "\n",
    "        # Return to physical space\n",
    "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class FNO2d(nn.Module):\n",
    "    def __init__(self, fno_architecture, device=None, padding_frac=1 / 4):\n",
    "        super(FNO2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "\n",
    "        input: the solution of the coefficient function and locations (a(x, y), x, y)\n",
    "        input shape: (batchsize, x=s, y=s, c=3)\n",
    "        output: the solution \n",
    "        output shape: (batchsize, x=s, y=s, c=1)\n",
    "        \"\"\"\n",
    "        self.modes1 = fno_architecture[\"modes\"]\n",
    "        self.modes2 = fno_architecture[\"modes\"]\n",
    "        self.width = fno_architecture[\"width\"]\n",
    "        self.n_layers = fno_architecture[\"n_layers\"]\n",
    "        self.retrain_fno = fno_architecture[\"retrain_fno\"]\n",
    "\n",
    "        torch.manual_seed(self.retrain_fno)\n",
    "        # self.padding = 9 # pad the domain if input is non-periodic\n",
    "        self.padding_frac = padding_frac\n",
    "        self.fc0 = nn.Linear(3, self.width)  # input channel is 3: (a(x, y), x, y)\n",
    "        \n",
    "        self.conv_list = nn.ModuleList(\n",
    "            [nn.Conv2d(self.width, self.width, 1) for _ in range(self.n_layers)])\n",
    "        self.spectral_list = nn.ModuleList(\n",
    "            [SpectralConv2d(self.width, self.width, self.modes1, self.modes2) for _ in range(self.n_layers)])\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        x1_padding = int(round(x.shape[-1] * self.padding_frac))\n",
    "        x2_padding = int(round(x.shape[-2] * self.padding_frac))\n",
    "        x = F.pad(x, [0, x1_padding, 0, x2_padding])\n",
    "\n",
    "        for k, (s, c) in enumerate(zip(self.spectral_list, self.conv_list)):\n",
    "\n",
    "            x1 = s(x)\n",
    "            x2 = c(x)\n",
    "            x = x1 + x2\n",
    "            if k != self.n_layers - 1:\n",
    "                x = F.gelu(x)\n",
    "        x = x[..., :-x1_padding, :-x2_padding]\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretization = 64\n",
    "\n",
    "x1_points = torch.linspace(x1_min, x1_max, discretization)\n",
    "x2_points = torch.linspace(x2_min, x2_max, discretization)\n",
    "\n",
    "position_grid = torch.stack(torch.meshgrid(x1_points, x2_points),axis=2).reshape((discretization, discretization, 2)).transpose(0, 1)\n",
    "\n",
    "d = 1\n",
    "n_samples = 32\n",
    "\n",
    "param_samples = torch.rand((n_samples, d))\n",
    "\n",
    "param_samples[:, 0] = param_samples[:, 0] * (dist_max-dist_min) + dist_min \n",
    "# param_samples[:, 0] = param_samples[:, 0] * (wl_max-wl_min) + wl_min \n",
    "\n",
    "fno_input_positions = torch.tile(position_grid.reshape((1, discretization**2, 2)), (n_samples, 1, 1))\n",
    "# print(fno_input_positions.shape)\n",
    "fno_input_params = torch.tile(param_samples.reshape(n_samples, 1, d), (1, discretization**2, 1))\n",
    "# print(fno_input_params.shape)\n",
    "fno_input_vectors = torch.concatenate((fno_input_positions, fno_input_params), axis=-1).reshape(n_samples*discretization*discretization, 2+d)\n",
    "# print(\"fno_input_vectors \", fno_input_vectors.shape)\n",
    "\n",
    "fno_input_train = torch.concatenate( (\n",
    "        u0(np.transpose(fno_input_vectors)).reshape((n_samples, discretization, discretization, 1)), \n",
    "        fno_input_vectors[:, 0].reshape((n_samples, discretization, discretization, 1)),\n",
    "        fno_input_vectors[:, 1].reshape((n_samples, discretization, discretization, 1))\n",
    "    ), axis=-1)\n",
    "\n",
    "fno_output_train = u(np.transpose(fno_input_vectors)).reshape((n_samples, discretization, discretization, 1))\n",
    "\n",
    "print(\"input:\", fno_input_train.shape)\n",
    "print(\"output:\", fno_output_train.shape)\n",
    "\n",
    "# np.savetxt(\"fno_input_vectors.csv\", np.array(fno_input_vectors.detach()), delimiter=',')\n",
    "\n",
    "n_train = int(0.8*n_samples)\n",
    "print(\"n_train = \", n_train)\n",
    "\n",
    "input_function_train = fno_input_train[:n_train, :, :, :]\n",
    "output_function_train = fno_output_train[:n_train, :, :, :]\n",
    "input_function_test = fno_input_train[n_train:, :, :, :]\n",
    "output_function_test = fno_output_train[n_train:, :, :, :]\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "training_set = DataLoader(TensorDataset(input_function_train, output_function_train), batch_size=batch_size, shuffle=False)\n",
    "testing_set = DataLoader(TensorDataset(input_function_test, output_function_test), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(input_function_train.shape)\n",
    "print(output_function_train.shape)\n",
    "print(input_function_test.shape)\n",
    "print(output_function_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "epochs = 10\n",
    "step_size = 20\n",
    "gamma = 0.5\n",
    "\n",
    "fno_architecture = {\n",
    "    \"modes\": 8,\n",
    "    \"width\": 32,\n",
    "    \"n_layers\": 2,\n",
    "    \"retrain_fno\": 1\n",
    "}\n",
    "\n",
    "fno = FNO2d(fno_architecture)\n",
    "\n",
    "optimizer = optim.Adam(fno.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "train_loss_mse = []\n",
    "test_loss_l2 = []\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,4))\n",
    "\n",
    "l = torch.nn.MSELoss()\n",
    "freq_print = 1\n",
    "for epoch in range(epochs):\n",
    "    train_mse = 0.0\n",
    "    for step, (input_batch, output_batch) in enumerate(training_set):\n",
    "        optimizer.zero_grad()\n",
    "        output_pred_batch = fno(input_batch).squeeze(2)\n",
    "        loss_f = l(output_pred_batch, output_batch)\n",
    "        loss_f.backward()\n",
    "        optimizer.step()\n",
    "        train_mse += loss_f.item()\n",
    "    train_mse /= len(training_set)\n",
    "    train_loss_mse.append(train_mse)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fno.eval()\n",
    "        test_relative_l2 = 0.0\n",
    "        for step, (input_batch, output_batch) in enumerate(testing_set):\n",
    "            output_pred_batch = fno(input_batch).squeeze(2)\n",
    "            loss_f = (torch.mean((output_pred_batch - output_batch) ** 2) / torch.mean(output_batch ** 2)) ** 0.5 * 100\n",
    "            test_relative_l2 += loss_f.item()\n",
    "        test_relative_l2 /= len(testing_set)\n",
    "        test_loss_l2.append(test_relative_l2)\n",
    "\n",
    "    if epoch % freq_print == 0: print(\"######### Epoch:\", epoch, \" ######### Train Loss:\", train_mse, \" ######### Relative L2 Test Norm:\", test_relative_l2)\n",
    "\n",
    "ax1.plot(train_loss_mse)\n",
    "ax1.set_title(\"Training loss (MSE)\")\n",
    "ax1.set_yscale('log')\n",
    "ax2.plot(test_loss_l2)\n",
    "ax2.set_title(\"Test loss (L2)\")\n",
    "ax2.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "\n",
    "test_input = fno_input_train[k:k+1, :, :, :]\n",
    "# input_FNO  = test_input[k:k+1, :, :, 0]\n",
    "\n",
    "prediction = fno.forward(test_input).reshape((discretization, discretization))\n",
    "ground_truth = fno_output_train[k, :, :, :].reshape((discretization, discretization))\n",
    "\n",
    "print(prediction.shape)\n",
    "print(ground_truth.shape)\n",
    "\n",
    "xx, yy = np.meshgrid(x1_points, x2_points)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 7))\n",
    "\n",
    "mirrored_xx = np.concatenate((xx, xx * -1), axis=0)\n",
    "mirrored_yy = np.concatenate((yy, yy), axis=0)\n",
    "\n",
    "dot_size = 5\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "im1 = ax1.scatter(mirrored_xx, mirrored_yy, c=np.concatenate((prediction.detach().numpy(),prediction.detach().numpy())), cmap=cm.jet, s=dot_size, vmin=-1, vmax=1)\n",
    "plt.colorbar(im1)\n",
    "ax1.set_xlabel('X1')\n",
    "ax1.set_ylabel('X2')\n",
    "ax1.set_title('FNO Prediction')\n",
    "ax1.set_xlim(-x1_max, x1_max)\n",
    "ax1.set_ylim(x2_min, x2_max)\n",
    "ax1.set_aspect(1)\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "im2 = ax2.scatter(mirrored_xx, mirrored_yy, c=np.concatenate((ground_truth.detach().numpy(),ground_truth.detach().numpy())), cmap=cm.jet, s=dot_size, vmin=-1, vmax=1)\n",
    "plt.colorbar(im2)\n",
    "ax2.set_xlabel('X1')\n",
    "ax2.set_ylabel('X2')\n",
    "ax2.set_title('Ground truth')\n",
    "ax2.set_xlim(-x1_max, x1_max)\n",
    "ax2.set_ylim(x2_min, x2_max)\n",
    "ax2.set_aspect(1)\n",
    "\n",
    "err_FNO = np.abs(ground_truth.detach().numpy()-prediction.detach().numpy())\n",
    "\n",
    "ax3 = fig.add_subplot(224)\n",
    "im3 = ax3.scatter(mirrored_xx, mirrored_yy, c=np.concatenate((err_FNO,err_FNO)), cmap=cm.jet, s=dot_size)\n",
    "plt.colorbar(im3)\n",
    "ax3.set_xlabel('X1')\n",
    "ax3.set_ylabel('X2')\n",
    "ax3.set_title('Error')\n",
    "ax3.set_xlim(-x1_max, x1_max)\n",
    "ax3.set_ylim(x2_min, x2_max)\n",
    "ax3.set_aspect(1)\n",
    "\n",
    "input_u0_FNO = test_input[0, :, :, 0].detach().numpy().reshape((discretization**2))\n",
    "input_u0_FNO = np.concatenate((input_u0_FNO, input_u0_FNO))\n",
    "\n",
    "ax4 = fig.add_subplot(223)\n",
    "im4 = ax4.scatter(mirrored_xx, mirrored_yy, c=input_u0_FNO, cmap=cm.binary, s=dot_size)\n",
    "plt.colorbar(im4)\n",
    "ax4.set_xlabel('X1')\n",
    "ax4.set_ylabel('X2')\n",
    "ax4.set_title(f'Input')\n",
    "ax4.set_xlim(-x1_max, x1_max)\n",
    "ax4.set_ylim(x2_min, x2_max)\n",
    "ax4.set_aspect(1)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
